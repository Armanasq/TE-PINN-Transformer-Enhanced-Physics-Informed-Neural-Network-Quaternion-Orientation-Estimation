# TE-PINN: Quaternion-Based Orientation Estimation ğŸš€

[![arXiv](https://img.shields.io/badge/arXiv-2409.16214-b31b1b.svg)](https://arxiv.org/abs/2409.16214)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

<div align="center">
  <img src="/images/tepinn_architecture.svg" alt="TE-PINN Architecture">
</div>

## ğŸ“Š Performance Highlights

| Metric | TE-PINN | Deep Learning Model | Improvement |
|--------|---------|-------------------|-------------|
| Mean Euler Error | 0.0195 | 0.0216 | -36.84% |
| Dynamic Error | 0.1677 | 0.1242 | -35.04% |
| Uncertainty Correlation | 0.0147 | 0.0553 | +73.44% |

## ğŸ” Overview

TE-PINN is a Transformer-Enhanced Physics-Informed Neural Network for quaternion-based orientation estimation in high-dynamic environments. Our approach combines:

- ğŸ§¬ Transformer architecture for temporal dependencies
- ğŸ“ Physics-informed constraints
- ğŸ¯ Quaternion kinematics
- ğŸ“ˆ Uncertainty quantification

## ğŸ—ï¸ Architecture

### Quaternion-Based Transformer Encoder

```python
x(táµ¢) = [Ï‰(táµ¢)áµ€, a(táµ¢)áµ€]áµ€
```

Positional Encoding:
```
P(i,2k) = sin(táµ¢/10000^(2k/dmodel))
P(i,2k+1) = cos(táµ¢/10000^(2k/dmodel))
```

### Physics-Informed Components

Rigid Body Dynamics:
```
I dÏ‰/dt + Ï‰ Ã— (IÏ‰) = Ï„
```

Quaternion Integration (RK4):
```
qw = cos(Ï•/2)cos(Î¸/2)
qx = sin(Ï•/2)cos(Î¸/2)
qy = cos(Ï•/2)sin(Î¸/2)
qz = sin(Ï•/2)sin(Î¸/2)
```

## ğŸ“ˆ Results

<div align="center">
  <img src="/images/performance_comparison.svg" alt="Performance Comparison">
</div>

### Error Metrics

```python
L_total = L_data + L_phys

where:
L_phys = Î»acc*L_acc + Î»gyro*L_gyro + Î»dynamics*L_dynamics
```

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/tepinn
cd tepinn
pip install -r requirements.txt
```

## ğŸ“Š Usage

```python
import tepinn

# Initialize model
model = tepinn.TEPINN(
    transformer_layers=6,
    heads=8,
    d_model=256
)

# Train model
model.train(imu_data, quaternion_gt)

# Inference
q_pred = model.predict(imu_sequence)
```

## ğŸ”¬ Experimental Results

### Ablation Study

| Component | Mean Error | Dynamic Error |
|-----------|------------|---------------|
| Base Model | 0.0216 | 0.1242 |
| + Transformer | 0.0205 | 0.1198 |
| + Physics | 0.0195 | 0.1677 |

### Parameter Settings

| Parameter | Value | Description |
|-----------|-------|-------------|
| Layers | 6 | Transformer encoder layers |
| Heads | 8 | Number of attention heads |
| d_model | 256 | Model dimension |
| Î»acc | 1.0 | Accelerometer loss weight |
| Î»gyro | 0.5 | Gyroscope loss weight |
| Î»dynamics | 0.1 | Dynamics loss weight |

## ğŸ¯ Key Features

1. **Multi-Head Attention**
   - Sequential IMU processing
   - Temporal dependency capture
   - Adaptive weighting

2. **Physics-Informed Learning**
   - Quaternion kinematics integration
   - Rigid body dynamics
   - RK4 numerical integration

3. **Uncertainty Quantification**
   - Evidential deep learning
   - Confidence estimation
   - Error calibration

## ğŸ”— Citation

```bibtex
@article{asgharpoor2024tepinn,
  title={TE-PINN: Quaternion-Based Orientation Estimation using Transformer-Enhanced Physics-Informed Neural Networks},
  author={Asgharpoor Golroudbari, Arman},
  journal={arXiv preprint arXiv:2409.16214},
  year={2024}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
